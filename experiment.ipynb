{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "import json\n",
                "import logging\n",
                "import random\n",
                "from pathlib import Path\n",
                "from typing import Optional\n",
                "\n",
                "from munch import Munch\n",
                "import numpy as np\n",
                "import torch\n",
                "from torch.utils.data import DataLoader\n",
                "import yaml\n",
                "\n",
                "from gtn import GTN\n",
                "from gtn.dataloader.graphbatch_collator import GraphBatchCollator\n",
                "from gtn.dataloader.graphdist_dataset import GraphDistDataset\n",
                "from gtn.dataloader.io import load_from_npz\n",
                "from gtn.dataloader.pyg_ged import get_pyg_ged_gcolls\n",
                "from gtn.model import aggregation, geometric_gnn\n",
                "from gtn.training.metrics import Metrics\n",
                "from gtn.training.optimizer import add_weight_decay\n",
                "from gtn.training.training import train\n",
                "from gtn.training.validation import evaluate"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "# Set up logging\n",
                "logger = logging.getLogger()\n",
                "logger.handlers = []\n",
                "ch = logging.StreamHandler()\n",
                "formatter = logging.Formatter(\n",
                "        fmt='%(asctime)s (%(levelname)s): %(message)s',\n",
                "        datefmt='%Y-%m-%d %H:%M:%S')\n",
                "ch.setFormatter(formatter)\n",
                "logger.addHandler(ch)\n",
                "logger.setLevel('INFO')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Configuration"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "source": [
                "with open('configs/aids_sinkhorn.yaml', 'r') as c:\n",
                "    config_seml = yaml.safe_load(c)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "source": [
                "config = Munch(config_seml['fixed'])\n",
                "\n",
                "language_src = 'en'\n",
                "language_tgt = 'es'\n",
                "data_dir = \"./data\"  # Download the data first, as described in the README\n",
                "\n",
                "variant = '1head'  # Single and multi-head variants: 1head, 8head\n",
                "config.update(config_seml[variant][\"fixed\"])\n",
                "\n",
                "config.nystrom = None if config.nystrom == \"None\" else config.nystrom\n",
                "config.sparse = None if config.sparse == \"None\" else config.sparse\n",
                "config.weight_decay = float(config.weight_decay)\n",
                "\n",
                "seed = 216871081\n",
                "test = False\n",
                "device = \"cuda\"  # Change to cpu if necessary"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "source": [
                "torch.manual_seed(seed)\n",
                "torch.cuda.manual_seed(seed)\n",
                "torch.cuda.manual_seed_all(seed)\n",
                "np.random.seed(seed)\n",
                "random.seed(seed)\n",
                "\n",
                "device = torch.device(device)\n",
                "graph_distance = config.graph_distance.lower()\n",
                "dataname = config.dataname.lower()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Load data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "source": [
                "# Load data\n",
                "data_path = Path.cwd() / \"data\"\n",
                "if dataname in [\"linux\"]:\n",
                "    dataname = dataname.upper()\n",
                "    gcolls, pair_idxs = get_pyg_ged_gcolls(\n",
                "        pyg_data_path, dataname, use_norm_ged=True, similarity=similarity\n",
                "    )\n",
                "else:\n",
                "    gcolls = {\n",
                "        dataset: load_from_npz(\n",
                "            data_path / f\"{dataname}_{graph_distance}_{dataset}.npz\"\n",
                "        )\n",
                "        for dataset in [\"train\", \"val\", \"test\"]\n",
                "    }\n",
                "    pair_idxs = {dataset: None for dataset in [\"train\", \"val\", \"test\"]}\n",
                "node_onehot = True\n",
                "if node_onehot:\n",
                "    node_feat_size = int(\n",
                "        max(\n",
                "            (\n",
                "                max((np.max(graph.attr_matrix) for graph in gcoll))\n",
                "                for gcoll in gcolls.values()\n",
                "            )\n",
                "        )\n",
                "        + 1\n",
                "    )\n",
                "else:\n",
                "    node_feat_size = gcolls[\"train\"][0].attr_matrix.shape[1]\n",
                "if gcolls[\"train\"][0].edge_attr_matrix is None:\n",
                "    edge_feat_size = 0\n",
                "else:\n",
                "    edge_feat_size = int(\n",
                "        max(\n",
                "            (\n",
                "                max((np.max(graph.edge_attr_matrix) for graph in gcoll))\n",
                "                for gcoll in gcolls.values()\n",
                "            )\n",
                "        )\n",
                "        + 1\n",
                "    )\n",
                "\n",
                "# Get datasets\n",
                "datasets = {}\n",
                "for key, gcoll in gcolls.items():\n",
                "    datasets[key] = GraphDistDataset(\n",
                "        gcoll,\n",
                "        node_feat_size,\n",
                "        edge_feat_size,\n",
                "        node_onehot=node_onehot,\n",
                "        edge_onehot=True,\n",
                "        pair_idx=pair_idxs[key],\n",
                "    )\n",
                "\n",
                "# Get dataloader\n",
                "collator = GraphBatchCollator()\n",
                "dataloaders = {}\n",
                "for key, dataset in datasets.items():\n",
                "    dataloaders[key] = DataLoader(\n",
                "        dataset,\n",
                "        batch_size=config.batch_size,\n",
                "        shuffle=True,\n",
                "        collate_fn=collator,\n",
                "        num_workers=1,\n",
                "    )"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "source": [
                "# Get Metrics\n",
                "metrics_list = [\"rmse\", \"cvrmse\", \"label_std\"]\n",
                "metrics_trackers = {\"iter\": {}, \"epoch\": {}}\n",
                "metric_to_stop_on = \"rmse\"\n",
                "minimize_stop_on = True\n",
                "patience = np.inf\n",
                "if config.get(\"print_step\", None) is not None:\n",
                "    metrics_trackers[\"iter\"][\"train\"] = Metrics(metrics_list)\n",
                "metrics_trackers[\"epoch\"][\"train\"] = Metrics(metrics_list)\n",
                "if config.get(\"print_step\", None) is not None:\n",
                "    metrics_trackers[\"iter\"][\"val\"] = Metrics(metrics_list)\n",
                "metrics_trackers[\"epoch\"][\"val\"] = Metrics(\n",
                "    metrics_list, metric_to_stop_on, minimize_stop_on, patience\n",
                ")\n",
                "metrics_trackers[\"epoch\"][\"test\"] = Metrics(metrics_list)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Set up model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "source": [
                "# Select activation function\n",
                "if config.act_fn == \"linear\":\n",
                "    act_fn = lambda x: x\n",
                "elif config.act_fn == \"relu\":\n",
                "    act_fn = torch.nn.functional.relu\n",
                "elif config.act_fn == \"sigmoid\":\n",
                "    act_fn = torch.nn.functional.sigmoid\n",
                "elif config.act_fn == \"leaky_relu\":\n",
                "    act_fn = torch.nn.functional.leaky_relu\n",
                "else:\n",
                "    raise ValueError(f\"Invalid act_fn '{config.act_fn}'.\")\n",
                "\n",
                "# Select layer aggregation function\n",
                "assert config.num_heads >= 1\n",
                "if config.num_heads == 1:\n",
                "    layer_aggregation = aggregation.MLP(\n",
                "        emb_size=config.emb_size, nlayers=config.nlayers, output_size=config.emb_size\n",
                "    )\n",
                "else:\n",
                "    layer_aggregation = aggregation.All()\n",
                "\n",
                "# Average degree used to prevent embedding magnitude changes in non-normalized aggregation\n",
                "avg_degree = np.mean([graph.adj_matrix.sum(1).mean() for graph in gcolls[\"train\"]])\n",
                "\n",
                "# Get GNN\n",
                "gnn = geometric_gnn.Net(\n",
                "    node_feat_size=node_feat_size,\n",
                "    edge_feat_size=edge_feat_size,\n",
                "    emb_size=config.emb_size,\n",
                "    nlayers=config.nlayers,\n",
                "    layer_aggregation=layer_aggregation,\n",
                "    device=device,\n",
                "    act_fn=act_fn,\n",
                "    avg_degree=avg_degree,\n",
                "    deg_norm_hidden=config.deg_norm_hidden,\n",
                ")\n",
                "\n",
                "# Statistics for normalizing embeddings used for Sinkhorn\n",
                "emb_dist_scale = np.mean(gcolls[\"train\"].dists.A[datasets[\"train\"].pair_idx])\n",
                "if config.extensive:\n",
                "    emb_dist_scale /= np.mean(\n",
                "        [\n",
                "            gcolls[\"train\"][idx].num_nodes()\n",
                "            for idx in datasets[\"train\"].pair_idx.flatten()\n",
                "        ]\n",
                "    )\n",
                "\n",
                "# Overall GTN model\n",
                "model = GTN(\n",
                "    gnn=gnn,\n",
                "    emb_dist_scale=emb_dist_scale,\n",
                "    device=device,\n",
                "    sinkhorn_reg=config.sinkhorn_reg,\n",
                "    sinkhorn_niter=config.sinkhorn_niter,\n",
                "    unbalanced_mode=config.unbalanced_mode,\n",
                "    nystrom=config.nystrom,\n",
                "    sparse=config.sparse,\n",
                "    extensive=config.extensive,\n",
                "    num_heads=config.num_heads,\n",
                "    multihead_scale_basis=config.get(\"multihead_scale_basis\", 1),\n",
                "    similarity=config.similarity,\n",
                ")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Training"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "source": [
                "# Training\n",
                "parameters = add_weight_decay(model, weight_decay=config.weight_decay)\n",
                "optimizer = torch.optim.Adam(parameters, lr=config.learning_rate)\n",
                "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
                "    optimizer, step_size=config.lr_stepsize, gamma=config.lr_gamma\n",
                ")\n",
                "\n",
                "result = {k: {} for k in metrics_list}\n",
                "result = train(\n",
                "    model,\n",
                "    device,\n",
                "    dataloaders,\n",
                "    optimizer,\n",
                "    lr_scheduler,\n",
                "    metrics_trackers,\n",
                "    num_epochs=config.num_epochs,\n",
                "    print_step=config.get(\"print_step\", None),\n",
                ")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-07-12 02:12:47 (INFO): Epoch 0/199,    train    loss: 206.2427, rmse: 14.3612, cvrmse: 0.2991, label_std: 14.0401 (21.52s)\n",
                        "2021-07-12 02:12:49 (INFO): Epoch 0/199,    val      loss: 36.3762, rmse: 6.0313, cvrmse: 0.1164, label_std: 15.8700 (2.10s)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/nfs/staff-ssd/klicpera/anaconda3/envs/pytorch1.4/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
                        "    send_bytes(obj)\n",
                        "  File \"/nfs/staff-ssd/klicpera/anaconda3/envs/pytorch1.4/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
                        "    self._send_bytes(m[offset:offset + size])\n",
                        "  File \"/nfs/staff-ssd/klicpera/anaconda3/envs/pytorch1.4/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
                        "    self._send(header + buf)\n",
                        "  File \"/nfs/staff-ssd/klicpera/anaconda3/envs/pytorch1.4/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
                        "    n = write(self._handle, buf)\n",
                        "BrokenPipeError: [Errno 32] Broken pipe\n"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-44-dea1ec9ea320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmetrics_trackers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mprint_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"print_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n",
                        "\u001b[0;32m~/graph-distance/gtn_public/gtn/training/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, dataloaders, optimizer, lr_scheduler, metrics_trackers, ex, print_step, num_epochs, config_str, save_weights)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/nfs/staff-ssd/klicpera/anaconda3/envs/pytorch1.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/graph-distance/gtn_public/gtn/gtn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph1, graph2)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         output = self._compute_matching(\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mcost_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_mat_len_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnystrom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnystrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         )\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/graph-distance/gtn_public/gtn/gtn.py\u001b[0m in \u001b[0;36m_compute_matching\u001b[0;34m(self, cost_mat, cost_mat_len, sparse, nystrom)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         return call_with_filtered_args(\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0msinkhorn_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msinkhorn_input_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mniter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msinkhorn_niter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         )\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/graph-distance/lcn_public/lcn/utils.py\u001b[0m in \u001b[0;36mcall_with_filtered_args\u001b[0;34m(function, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_function_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionMeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/graph-distance/lcn_public/lcn/sinkhorn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, cost_mat, num_points, sinkhorn_reg, niter, offset_entropy)\u001b[0m\n\u001b[1;32m    104\u001b[0m     ):\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mT_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_log_sinkhorn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msinkhorn_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Evaluation"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "source": [
                "logging.info(\"Evaluating on test\")\n",
                "result_test = evaluate(\n",
                "    model,\n",
                "    device,\n",
                "    dataloaders[\"test\"],\n",
                "    metrics_trackers[\"epoch\"][\"test\"],\n",
                "    disable_tqdm=False,\n",
                ")\n",
                "for key in metrics_list:\n",
                "    result[key][\"test\"] = result_test[key]"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-07-12 02:15:37 (INFO): Evaluating on test\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "89f1931802de4e459e7a45da462f749c"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-07-12 02:15:40 (INFO): loss: 40.9043, rmse: 6.3956, cvrmse: 0.1320, label_std: 13.9971 (2.94s)\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "source": [
                "logging.info(result)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-07-12 02:15:43 (INFO): {'loss': {'test': 40.904275630382784}, 'rmse': {'test': 6.395645}, 'cvrmse': {'test': 0.13199443281115636}, 'label_std': {'test': 13.997074}}\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
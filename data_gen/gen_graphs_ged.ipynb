{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from gtn.dataloader.graphcollection import GraphCollection\n",
    "from gtn.dataloader.preprocessing import networkx_to_sparsegraph\n",
    "\n",
    "from graph_gen import initial_attractiveness\n",
    "from ged import calc_all_geds, calc_ged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_state = np.random.RandomState(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 clusters: 12 train, 4 val, 4 test\n",
    "ngraphs = 20\n",
    "min_nodes = 10000\n",
    "total_nodes = np.arange(1 * min_nodes, 3 * min_nodes, dtype=int)\n",
    "initial_nodes = np.arange(1, 5, dtype=int)\n",
    "initial_attr = np.arange(5, dtype=int)\n",
    "\n",
    "nx_graphs = []\n",
    "for _ in range(ngraphs):\n",
    "    n = rnd_state.choice(total_nodes)\n",
    "    m = rnd_state.choice(initial_nodes)\n",
    "    A = rnd_state.choice(initial_attr)\n",
    "    nx_graphs.append(initial_attractiveness(n, m, A, rnd_state=rnd_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: mean nodes: 21781.25, edges: 41542.42\n",
      "Val:   mean nodes: 19925.50, edges: 60196.75\n",
      "Test:  mean nodes: 18257.50, edges: 39482.50\n"
     ]
    }
   ],
   "source": [
    "ns = [graph.number_of_nodes() for graph in nx_graphs]\n",
    "es = [graph.number_of_edges() for graph in nx_graphs]\n",
    "\n",
    "print(f\"Train: mean nodes: {np.mean(ns[:12]):.2f}, edges: {np.mean(es[:12]):.2f}\")\n",
    "print(f\"Val:   mean nodes: {np.mean(ns[12:16]):.2f}, edges: {np.mean(es[12:16]):.2f}\")\n",
    "print(f\"Test:  mean nodes: {np.mean(ns[16:]):.2f}, edges: {np.mean(es[16:]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_graph(graph, num_nodelabels, num_edgelabels):\n",
    "    nodelabels = rnd_state.randint(num_nodelabels, size=len(graph.nodes))\n",
    "    for i, label in enumerate(nodelabels):\n",
    "        graph.nodes[i]['label'] = label\n",
    "    \n",
    "    if num_edgelabels is not None:\n",
    "        edgelabels = rnd_state.randint(num_edgelabels, size=len(graph.edges))\n",
    "        for i, (n1, n2) in enumerate(graph.edges):\n",
    "            graph.edges[n1, n2]['label'] = edgelabels[i]\n",
    "        \n",
    "num_nodelabels = 6\n",
    "num_edgelabels = None #4\n",
    "\n",
    "for graph in nx_graphs:\n",
    "    label_graph(graph, num_nodelabels, num_edgelabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nx = nx_graphs[:12]\n",
    "val_nx = nx_graphs[12:16]\n",
    "test_nx = nx_graphs[16:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit graphs to generate trees (clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_graph(graph, num_nodelabels, num_edgelabels):\n",
    "    edit_types = ['node_edit', 'node_add']\n",
    "    edit_probs = np.array([4, 1], dtype=float)\n",
    "    if graph.number_of_nodes() > 2:\n",
    "        edit_types += ['node_del']\n",
    "        edit_probs = np.append(edit_probs, 1)\n",
    "    max_nedges = graph.number_of_nodes() * (graph.number_of_nodes() - 1) / 2\n",
    "    if (graph.number_of_nodes() > 1\n",
    "            and graph.number_of_edges() < max_nedges):\n",
    "        edit_types += ['edge_add']\n",
    "        edit_probs = np.append(edit_probs, 3)\n",
    "    if graph.number_of_edges() > 0 and num_edgelabels is not None:\n",
    "        edit_types += ['edge_edit']\n",
    "        edit_probs = np.append(edit_probs, 4)\n",
    "    if graph.number_of_edges() > 1:\n",
    "        edit_types += ['edge_del']\n",
    "        edit_probs = np.append(edit_probs, 3)\n",
    "    edit_probs /= edit_probs.sum()\n",
    "    \n",
    "    edit_type = rnd_state.choice(edit_types, p=edit_probs)\n",
    "    \n",
    "    if edit_type == 'node_edit':\n",
    "        inode = rnd_state.choice(graph.nodes)\n",
    "        graph.nodes[inode]['label'] = rnd_state.randint(num_nodelabels)\n",
    "        \n",
    "    elif edit_type == 'node_add':\n",
    "        # Add a node with 2 edges\n",
    "        iadd = [inode for inode in range(graph.number_of_nodes() + 1) if inode not in graph.nodes][0]\n",
    "        connect_probs = np.array(list(dict(graph.degree).values()), dtype=float)  # Corresponds to Barabasi-Albert\n",
    "        connect_probs /= connect_probs.sum()\n",
    "        iconnects = rnd_state.choice(graph.nodes, p=connect_probs, size=2, replace=False)\n",
    "        iadds = np.repeat(iadd, 2)\n",
    "        graph.add_edges_from(zip(iadds, iconnects))\n",
    "        if num_edgelabels is not None:\n",
    "            for pair_idx in zip(*(iadds, iconnects)):\n",
    "                graph.edges[pair_idx]['label'] = rnd_state.randint(num_edgelabels)\n",
    "        graph.nodes[iadd]['label'] = rnd_state.randint(num_nodelabels)\n",
    "        \n",
    "    elif edit_type == 'node_del':\n",
    "        del_probs = 1 / (np.array(list(dict(graph.degree).values())) + 1)  # Inverse Initial Attractiveness with A=1\n",
    "        del_probs /= del_probs.sum()\n",
    "        inode = rnd_state.choice(graph.nodes, p=del_probs)\n",
    "        graph.remove_node(inode)\n",
    "        \n",
    "    elif edit_type == 'edge_edit':\n",
    "        iedge = rnd_state.choice(len(graph.edges))\n",
    "        edge_idx = list(graph.edges)[iedge]\n",
    "        graph.edges[edge_idx]['label'] = rnd_state.randint(num_edgelabels)\n",
    "        \n",
    "    elif edit_type == 'edge_add':\n",
    "        connect_probs = np.array(list(dict(graph.degree).values()), dtype=float)  # Corresponds to Barabasi-Albert\n",
    "        connect_probs /= connect_probs.sum()\n",
    "        iconnects = rnd_state.choice(graph.nodes, p=connect_probs, size=2, replace=False)\n",
    "        while graph.has_edge(*iconnects):\n",
    "            iconnects = rnd_state.choice(graph.nodes, p=connect_probs, size=2, replace=False)\n",
    "        graph.add_edge(*iconnects)\n",
    "        if num_edgelabels is not None:\n",
    "            graph.edges[iconnects]['label'] = rnd_state.randint(num_edgelabels)\n",
    "        \n",
    "    elif edit_type == 'edge_del':\n",
    "        iedge = rnd_state.choice(len(graph.edges))\n",
    "        edge_idx = list(graph.edges)[iedge]\n",
    "        graph.remove_edge(*edge_idx)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown edit type: {edit_type}\")\n",
    "\n",
    "\n",
    "def gen_edited_graph(graphs, num_nodelabels, num_edgelabels, min_edits=2, max_edits=5):\n",
    "    g = nx_graphs[rnd_state.randint(len(nx_graphs))].copy()\n",
    "    nedits = rnd_state.randint(min_edits, max_edits + 1)\n",
    "    for _ in range(nedits):\n",
    "        edit_graph(g, num_nodelabels, num_edgelabels)\n",
    "        \n",
    "    # Sanitize node labels\n",
    "    relabel_dict = dict(zip(g.nodes, np.arange(g.number_of_nodes())))\n",
    "    g = nx.relabel_nodes(g, relabel_dict)\n",
    "    \n",
    "    return g\n",
    "    \n",
    "\n",
    "def add_graph_variants(graphs, nadd, num_nodelabels, num_edgelabels, min_edits, max_edits):\n",
    "    for _ in range(nadd):\n",
    "        graphs.append(gen_edited_graph(graphs, num_nodelabels, num_edgelabels, min_edits, max_edits))\n",
    "\n",
    "min_edits = min_nodes // 20\n",
    "max_edits = min_nodes // 10\n",
    "add_graph_variants(train_nx, len(train_nx) * 11, num_nodelabels, num_edgelabels, min_edits, max_edits)\n",
    "add_graph_variants(val_nx, len(val_nx) * 11, num_nodelabels, num_edgelabels, min_edits, max_edits)\n",
    "add_graph_variants(test_nx, len(test_nx) * 11, num_nodelabels, num_edgelabels, min_edits, max_edits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset lengths: [144, 48, 48]\n",
      "Train edges: [10529, 28355, 75963, 12792, 59805, 23796, 79358, 44318, 90131, 28885, 22105, 22472, 75802, 74193, 74232, 35669, 28410, 35599, 22116, 54933, 22536, 22202, 33406, 57617, 57411, 12846, 75813, 20356, 59738, 44159, 22207, 59742, 28964, 33475, 46502, 74953, 74282, 54976, 10635, 35745, 12788, 12756, 74874, 10586, 20372, 10545, 28932, 59776, 22484, 46683, 74865, 89796, 22151, 20389, 54939, 79111, 33487, 46605, 54921, 22126, 12863, 54980, 59747, 20467, 75003, 35701, 54988, 12801, 23795, 75813, 20423, 35675, 28412, 46600, 89925, 75823, 89890, 54948, 28344, 22149, 28859, 44151, 74089, 44194, 12795, 59750, 33419, 22480, 20366, 46588, 44194, 74185, 28304, 89892, 79278, 28920, 10545, 74961, 23813, 20414, 12812, 44147, 44179, 79021, 10651, 54955, 54958, 74945, 44191, 22435, 20442, 78986, 46597, 33436, 28890, 75768, 12832, 54966, 28416, 89796, 22537, 79096, 74923, 57499, 28428, 46663, 33407, 23819, 28944, 28932, 12839, 89895, 59825, 28381, 74201, 46600, 28376, 22161, 74225, 22157, 35682, 89739, 89770, 23838]\n",
      "Train: mean nodes, edges: [20913.465277777777, 44160.541666666664]\n",
      "Val:   mean nodes: [19617.145833333332, 45858.666666666664]\n",
      "Test:  mean nodes: [19848.5, 47690.583333333336]\n"
     ]
    }
   ],
   "source": [
    "def nnodes_nedges(nx_graphs):\n",
    "    ns = [graph.number_of_nodes() for graph in nx_graphs]\n",
    "    es = [graph.number_of_edges() for graph in nx_graphs]\n",
    "    return ns, es\n",
    "\n",
    "print(f\"Dataset lengths: {[len(dataset) for dataset in [train_nx, val_nx, test_nx]]}\")\n",
    "print(f\"Train edges: {nnodes_nedges(train_nx)[1]}\")\n",
    "print(f\"Train: mean nodes, edges: {[np.mean(ns) for ns in nnodes_nedges(train_nx)]}\")\n",
    "print(f\"Val:   mean nodes: {[np.mean(ns) for ns in nnodes_nedges(val_nx)]}\")\n",
    "print(f\"Test:  mean nodes: {[np.mean(ns) for ns in nnodes_nedges(test_nx)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to SparseGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_to_gcoll(nx_graphs):\n",
    "    gcoll = GraphCollection()\n",
    "    for nx_graph in nx_graphs:\n",
    "        sp_graph = networkx_to_sparsegraph(nx_graph, sparse_node_attrs=False, sparse_edge_attrs=False)\n",
    "        gcoll.append(sp_graph)\n",
    "    return gcoll\n",
    "\n",
    "gcoll_train = nx_to_gcoll(train_nx)\n",
    "gcoll_val = nx_to_gcoll(val_nx)\n",
    "gcoll_test = nx_to_gcoll(test_nx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as GraphCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "gust.io.save_to_npz(f\"pref_att_{min_nodes}_train.npz\", gcoll_train)\n",
    "gust.io.save_to_npz(f\"pref_att_{min_nodes}_val.npz\", gcoll_val)\n",
    "gust.io.save_to_npz(f\"pref_att_{min_nodes}_test.npz\", gcoll_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check consistency of NetworkX conversion and npz-loading/saving\n",
    "gcoll2 = gust.io.load_from_npz(f\"pref_att_{min_nodes}_train.npz\")\n",
    "for i, sp_graph in enumerate(gcoll2):\n",
    "    nx_graph2 = gust.sparsegraph_to_networkx(sp_graph)\n",
    "    if not (nx_graph2.nodes.data() == train_nx[i].nodes.data()):\n",
    "        print(\"Node error\")\n",
    "    if num_edgelabels is None:\n",
    "        for j, (u, v, data2) in enumerate(nx_graph2.edges.data()):\n",
    "            # Weight entry in gcoll2, but not in train_nx. Problem?\n",
    "            if not (u, v) in train_nx[i].edges:\n",
    "                print(\"Edge error\")\n",
    "    else:\n",
    "        for j, (u, v, data2) in enumerate(nx_graph2.edges.data()):\n",
    "            if not (int(data2['label']) == train_nx[i].edges[u, v]['label']):\n",
    "                print(\"Edge error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate graph edit distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set costs for all edit operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_node_subst(node_i, node_j):\n",
    "    return 0 if node_i == node_j else 1\n",
    "def cost_edge_subst(edge_i, edge_j):\n",
    "    return 0 if edge_i == edge_j else 1\n",
    "costs = {'node_subst': cost_node_subst, 'node_del': 2, 'node_ins': 2,\n",
    "         'edge_subst': cost_edge_subst, 'edge_del': 2, 'edge_ins': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the graph edit distance by solving the following binary linear program:\n",
    "\\begin{align*}\n",
    "    \\underset{\\mathbf{x}, \\mathbf{y}}{\\text{min}} \\quad& \\left[ \\sum_{i \\in V_1} \\sum_{k \\in V_2} \\left( c_{i,k} - c_{i,\\epsilon} - c_{\\epsilon,k} \\right) x_{i,k} + \\sum_{ij \\in E_1} \\sum_{kl \\in E_2} \\left( c_{ij,kl} - c_{ij,\\epsilon} - c_{\\epsilon,kl} \\right) y_{ij,kl} \\right] + \\gamma\\\\\n",
    "    \\text{with} \\quad& \\gamma = \\sum_{i \\in V_1} c_{i,\\epsilon} + \\sum_{k \\in V_2} c_{\\epsilon,k} + \\sum_{ij \\in E_1} c_{ij,\\epsilon} + \\sum_{kl \\in E_2} c_{\\epsilon,kl}\\\\\n",
    "    \\text{subject to} \\quad& \\sum_{k \\in V_2} x_{i,k} \\le 1 \\quad\\quad \\forall i \\in V_1\\\\\n",
    "    & \\sum_{i \\in V_1} x_{i,k} \\le 1 \\quad\\quad \\forall k \\in V_2\\\\\n",
    "    & \\sum_{kl \\in E_2} y_{ij,kl} - x_{i,k} \\le 0 \\quad\\quad \\forall k \\in V_2 ,\\; \\forall ij \\in E_1\\\\\n",
    "    & \\sum_{kl \\in E_2} y_{ij,kl} - x_{j,l} \\le 0 \\quad\\quad \\forall l \\in V_2 ,\\; \\forall ij \\in E_1\\\\\n",
    "    \\text{with} \\quad& x_{i,k} \\in \\{0,1\\} \\quad\\quad \\forall (i,k) \\in V_1 \\times V_2\\\\\n",
    "    & y_{ij,kl} \\in \\{0,1\\} \\quad\\quad \\forall (ij,kl) \\in E_1 \\times E_2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt\n",
    "from cvxopt.glpk import ilp\n",
    "\n",
    "def calc_ged_prototype(graph1, graph2, costs, timelimit=None):\n",
    "    \"\"\"\n",
    "    Calculate the graph edit distance between two NetworkX graphs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph1 : NetworkX graph\n",
    "        Graph, where all nodes and features have a 'label' attribute, which is an integer.\n",
    "        \n",
    "    graph2 : NetworkX graph\n",
    "        Graph, where all nodes and features have a 'label' attribute, which is an integer.\n",
    "        \n",
    "    costs: dict\n",
    "        Dictionary containing entries for all edit costs:\n",
    "        'node_subst': Function: [Number, Number] -> Number\n",
    "        'node_del': float\n",
    "        'node_ins': float\n",
    "        'edge_subst': Function: [Number, Number] -> Number\n",
    "        'edge_del': float\n",
    "        'edge_ins': float\n",
    "        \n",
    "    timelimit: int\n",
    "        Timelimit of the glpk solver in seconds\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dist : float\n",
    "        Graph edit distance between the graphs\n",
    "        \n",
    "    nodes_perm : list(integer tuples)\n",
    "        Permutation of nodes from graph1 to graph2\n",
    "        \n",
    "    edges_perm : list(tuples of integer tuples)\n",
    "        Permutation of edges from graph1 to graph2\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create costs vector c\n",
    "    costs_nodes = np.zeros([graph1.number_of_nodes(), graph2.number_of_nodes()])\n",
    "    costs_nodes -= costs['node_del'] + costs['node_ins']\n",
    "    for i, data_i in graph1.nodes().data():\n",
    "        for k, data_k in graph2.nodes().data():\n",
    "            costs_nodes[i, k] += costs['node_subst'](data_i['label'], data_k['label'])\n",
    "    \n",
    "    costs_edges = np.zeros([graph1.number_of_edges(), graph2.number_of_edges()])\n",
    "    costs_edges -= costs['edge_del'] + costs['edge_ins']\n",
    "    for id1, (i, j, data_ij) in enumerate(graph1.edges().data()):\n",
    "        for id2, (k, l, data_kl) in enumerate(graph2.edges().data()):\n",
    "            costs_edges[id1, id2] += costs['edge_subst'](data_ij['label'], data_kl['label'])\n",
    "    \n",
    "    c = cvxopt.matrix(np.concatenate([costs_nodes.flatten(), costs_edges.flatten()]))\n",
    "    x_size = costs_nodes.size + costs_edges.size\n",
    "    \n",
    "    # Create constraints vector h\n",
    "    h_nodes = np.ones(graph1.number_of_nodes() + graph2.number_of_nodes())\n",
    "    h_edges = np.zeros(2 * graph2.number_of_nodes() * graph1.number_of_edges())\n",
    "    h = cvxopt.matrix(np.concatenate([h_nodes, h_edges]))\n",
    "    \n",
    "    # Create constraints matrix G\n",
    "    G = np.zeros([h_nodes.size + h_edges.size, x_size])\n",
    "    row = -1\n",
    "    for i in graph1.nodes():\n",
    "        row += 1\n",
    "        for k in graph2.nodes():\n",
    "            G[row, np.ravel_multi_index([i, k], costs_nodes.shape)] = 1\n",
    "    for k in graph2.nodes():\n",
    "        row += 1\n",
    "        for i in graph1.nodes():\n",
    "            G[row, np.ravel_multi_index([i, k], costs_nodes.shape)] = 1\n",
    "    for k in graph2.nodes():\n",
    "        for id1, (i, j) in enumerate(graph1.edges()):\n",
    "            row += 1\n",
    "            G[row, np.ravel_multi_index([i, k], costs_nodes.shape)] = -1\n",
    "            for id2, (k_edge, l) in enumerate(graph2.edges()):\n",
    "                if k == k_edge:\n",
    "                    G[row, costs_nodes.size + np.ravel_multi_index([id1, id2], costs_edges.shape)] = 1\n",
    "    for l in graph2.nodes():\n",
    "        for id1, (i, j) in enumerate(graph1.edges()):\n",
    "            row += 1\n",
    "            G[row, np.ravel_multi_index([j, l], costs_nodes.shape)] = -1\n",
    "            for id2, (k, l_edge) in enumerate(graph2.edges()):\n",
    "                if l == l_edge:\n",
    "                    G[row, costs_nodes.size + np.ravel_multi_index([id1, id2], costs_edges.shape)] = 1\n",
    "    G_cvxopt = cvxopt.matrix(G)\n",
    "    \n",
    "    # Create indices for integer/binary variables (everything's binary)\n",
    "    I = set()\n",
    "    B = set(range(x_size))\n",
    "    \n",
    "    # Solve binary linear problem\n",
    "    if timelimit is None:\n",
    "        options = None\n",
    "    else:\n",
    "        options = {'tm_lim': timelimit * 1000}\n",
    "    status, x = ilp(c, G_cvxopt, h, None, None, I, B, options=options)\n",
    "    # print(status)\n",
    "    \n",
    "    # Transform node indices\n",
    "    x_ik = np.reshape(x[:costs_nodes.size], costs_nodes.shape)\n",
    "    assert np.all((0 <= x_ik.sum(axis=0)) & (x_ik.sum(axis=0) <= 1)), \"Node assignment column sum outside allowed range (0, 1)\"\n",
    "    assert np.all((0 <= x_ik.sum(axis=1)) & (x_ik.sum(axis=1) <= 1)), \"Node assignment row sum outside allowed range (0, 1)\"\n",
    "    nodes_transf = [None, None]\n",
    "    nodes_transf[0], nodes_transf[1] = np.where(x_ik > 0)\n",
    "    nodes_transf[0] = list(nodes_transf[0])\n",
    "    nodes_transf[1] = list(nodes_transf[1])\n",
    "    \n",
    "    # Transform edge indices\n",
    "    y_id1id2 = np.reshape(x[costs_nodes.size:], costs_edges.shape)\n",
    "    assert np.all((0 <= y_id1id2.sum(axis=0)) & (y_id1id2.sum(axis=0) <= 1)), \"Edge assignment column sum outside allowed range (0, 1)\"\n",
    "    assert np.all((0 <= y_id1id2.sum(axis=1)) & (y_id1id2.sum(axis=1) <= 1)), \"Edge assignment row sum outside allowed range (0, 1)\"\n",
    "    edges_id_perm = zip(*np.where(y_id1id2 > 0))\n",
    "    edges_transf = [[], []]\n",
    "    edges1 = list(graph1.edges())\n",
    "    edges2 = list(graph2.edges())\n",
    "    for id1, id2 in edges_id_perm:\n",
    "        edges_transf[0].append(edges1[id1])\n",
    "        edges_transf[1].append(edges2[id2])\n",
    "    \n",
    "    # Calculate graph edit distance\n",
    "    dist = ((x_ik * costs_nodes).sum() + (y_id1id2 * costs_edges).sum()\n",
    "            + graph1.number_of_nodes() * costs['node_del'] + graph2.number_of_nodes() * costs['node_ins']\n",
    "            + graph1.number_of_edges() * costs['edge_del'] + graph2.number_of_edges() * costs['edge_ins'])\n",
    "    \n",
    "    # Add entries for insertions and deletions\n",
    "    for node in graph1.nodes():\n",
    "        if node not in nodes_transf[0]:\n",
    "            nodes_transf[0].append(node)\n",
    "            nodes_transf[1].append(np.nan)\n",
    "    for node in graph2.nodes():\n",
    "        if node not in nodes_transf[1]:\n",
    "            nodes_transf[0].append(np.nan)\n",
    "            nodes_transf[1].append(node)\n",
    "    for edge in graph1.edges():\n",
    "        if edge not in edges_transf[0]:\n",
    "            edges_transf[0].append(edge)\n",
    "            edges_transf[1].append(np.nan)\n",
    "    for edge in graph2.edges():\n",
    "        if edge not in edges_transf[1]:\n",
    "            edges_transf[0].append(np.nan)\n",
    "            edges_transf[1].append(edge)\n",
    "    \n",
    "    # Transform permutation list\n",
    "    nodes_perm = list(zip(*nodes_transf))\n",
    "    edges_perm = list(zip(*edges_transf))\n",
    "        \n",
    "    return dist, nodes_perm, edges_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. 35.]\n",
      " [35.  0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/klicpera/anaconda3/envs/graph/lib/python3.6/site-packages/scipy/sparse/compressed.py:746: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "calc_all_geds(gcoll, costs, nprocesses=4, timelimit=1000)\n",
    "print(gcoll.dists.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = gust.sparsegraph_to_networkx(gcoll[0])\n",
    "g2 = gust.sparsegraph_to_networkx(gcoll[1])\n",
    "dist, nodes_perm, edges_perm = calc_ged_prototype(g1, g2, costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}